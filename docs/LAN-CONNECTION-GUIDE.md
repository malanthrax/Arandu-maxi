# LAN Connection Guide - Client-Specific URL Formats

## Critical Finding: Each Program Requires Different URL Styles for LAN

**Your LAN Setup:**
- Host PC (running model): `10.0.0.106`
- Client PC (running Witsy/Cherry): `10.0.0.47`
- OpenAI Proxy Port: `8081` (or 8091 if configured)

---

## ‚úÖ WORKING CONFIGURATIONS

### **Witsy - LAN Connection**

**Working URL:**
```
http://10.0.0.119:8084/v1/
```

**Key Requirements:**
- ‚úÖ **Must include** `/v1/` suffix
- ‚úÖ **Must include** trailing slash `/` at the very end
- ‚úÖ Use the **host PC's actual IP** (not 127.0.0.1)
- ‚úÖ Format: `http://IP:PORT/v1/` (can be port 8081, 8084, or any configured port)

**Settings:**
- Base URL: `http://10.0.0.119:8084/v1/`
- API Key: (leave empty)
- Model: (auto-detected)

**What Works:**
- ‚úÖ `http://10.0.0.119:8084/v1/` ‚Üê **CORRECT** (slash after v1!)

**What Does NOT Work:**
- ‚ùå `http://10.0.0.119:8084` (missing /v1/)
- ‚ùå `http://10.0.0.119:8084/v1` (missing trailing slash after v1)
- ‚ùå `http://10.0.0.119:8084/v1` (missing ending slash)
- ‚ùå `http://127.0.0.1:8084/v1/` (wrong IP for LAN)

---

### **Cherry Studio AI - LAN Connection**

**Working URL:**
```
http://10.0.0.106:8086
```

**Key Requirements:**
- ‚úÖ **NO /v1 suffix** at all
- ‚úÖ **NO trailing slash** at the end
- ‚úÖ Use the **host PC's actual IP**
- ‚úÖ Just the base URL with port (can be 8081, 8086, or any configured port)

**Settings:**
- Base URL: `http://10.0.0.106:8086`
- API Key: (leave empty)

**What Works:**
- ‚úÖ `http://10.0.0.106:8086` ‚Üê **CORRECT** (no ending slash!)

**What Does NOT Work:**
- ‚ùå `http://10.0.0.106:8086/` (has trailing slash)
- ‚ùå `http://10.0.0.106:8086/v1` (includes /v1)
- ‚ùå `http://127.0.0.1:8086` (wrong IP for LAN)

---

### **Python OpenAI SDK - LAN Connection**

**Working URL:**
```python
http://10.0.0.106:8081/v1
```

**Key Requirements:**
- ‚úÖ **Include** `/v1` suffix
- ‚úÖ **NO trailing slash**
- ‚úÖ Use host PC's actual IP

**Example:**
```python
from openai import OpenAI

client = OpenAI(
    base_url="http://10.0.0.106:8081/v1",  # ‚Üê Note: /v1 without trailing slash
    api_key="not-needed"
)
```

**What Works:**
- ‚úÖ `http://10.0.0.106:8081/v1` ‚Üê **CORRECT**

**What Does NOT Work:**
- ‚ùå `http://10.0.0.106:8081/v1/` (has trailing slash)
- ‚ùå `http://10.0.0.106:8081` (missing /v1)

---

### **Curl / HTTP Clients - LAN Connection**

**Working URL:**
```bash
http://10.0.0.106:8081/v1/models
http://10.0.0.106:8081/v1/chat/completions
```

**Key Requirements:**
- ‚úÖ Standard OpenAI format works
- ‚úÖ Full path including endpoint

---

## üìã SUMMARY TABLE - CONFIRMED WORKING FORMATS

| Client | URL Format | /v1 Required | Trailing Slash | Working Example |
|--------|-----------|--------------|----------------|-----------------|
| **Witsy** | `http://IP:PORT/v1/` | ‚úÖ YES | ‚úÖ YES | `http://10.0.0.119:8084/v1/` |
| **Cherry Studio AI** | `http://IP:PORT` | ‚ùå NO | ‚ùå NO | `http://10.0.0.106:8086` |
| **Python SDK** | `http://IP:PORT/v1` | ‚úÖ YES | ‚ùå NO | `http://10.0.0.106:8081/v1` |
| **Curl** | `http://IP:PORT/v1/endpoint` | ‚úÖ YES | N/A | `http://10.0.0.106:8081/v1/models` |

---

## üéØ COMMON MISTAKES

### **Mistake 1: Using localhost IP for LAN**
‚ùå `http://127.0.0.1:8081/v1/` ‚Üê Won't work across LAN  
‚úÖ `http://10.0.0.106:8081/v1/` ‚Üê Use host PC's actual IP

### **Mistake 2: Wrong /v1 suffix**
‚ùå `http://10.0.0.106:8081` (Witsy - needs /v1/)  
‚ùå `http://10.0.0.106:8081/v1` (Cherry AI - shouldn't have /v1)  

### **Mistake 3: Wrong trailing slash**
‚ùå `http://10.0.0.106:8081/v1` (Witsy - needs trailing slash)  
‚ùå `http://10.0.0.106:8081/` (Cherry AI - shouldn't have trailing slash)

### **Mistake 4: Port mismatch**
‚ùå `http://10.0.0.106:8080` ‚Üê Wrong port (8080 is llama.cpp)  
‚úÖ `http://10.0.0.106:8081` ‚Üê Correct port (OpenAI Proxy)

---

## üîß SETUP CHECKLIST

**On Host PC (running model):**
1. ‚úÖ Launch Arandu
2. ‚úÖ Double-click a GGUF model to load it
3. ‚úÖ Wait for "HTTP server is listening"
4. ‚úÖ Click "Network Serve" widget
5. ‚úÖ Click "Activate"
6. ‚úÖ Note the LAN IP shown (e.g., `10.0.0.106`)

**On Client PC (running Witsy/Cherry):**
7. ‚úÖ Open Windows Firewall (if needed)
8. ‚úÖ Allow Arandu.exe through firewall on host PC
9. ‚úÖ Configure client with EXACT URL format above
10. ‚úÖ Test connection

---

## üß™ TESTING CONNECTIONS

**Test from Client PC:**
```bash
# Test 1: Check if port is open
curl http://10.0.0.106:8081/health

# Test 2: List models
curl http://10.0.0.106:8081/v1/models

# Test 3: Chat completion
curl -X POST http://10.0.0.106:8081/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"llama-model","messages":[{"role":"user","content":"Hello"}]}'
```

**If curl works but client doesn't:** Double-check the exact URL format for that specific client!

---

## üìù NOTES

- **The /v1 suffix handling varies by client** - some require it, some don't
- **Trailing slashes matter** - Witsy requires it, Cherry AI breaks with it
- **Always use the host PC's actual LAN IP** (10.0.0.x, 192.168.1.x, etc.)
- **Port 8081** is the OpenAI Proxy port (NOT 8080 which is llama.cpp internal)
- **CORS is enabled** in latest build for browser-based clients

---

**Version:** 0.5.5-beta  
**Date:** 2025-02-22  
**Tested With:** Witsy, Cherry AI, Python OpenAI SDK, curl
